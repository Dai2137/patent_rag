"""
Patent Quote Highlighter (LLM Version)
ç‰¹è¨±ã®ãƒ•ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¼•ç”¨æ–‡ã‚’ç‰¹å®šã—ã€å¼·èª¿è¡¨ç¤ºã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆLLMç‰ˆï¼‰

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€è¨¼æ‹ æŠ½å‡ºçµæœï¼ˆevidence_itemsï¼‰ã«å«ã¾ã‚Œã‚‹quoteã‚’å…ƒã®ç‰¹è¨±æ–‡çŒ®ã‹ã‚‰æ¤œç´¢ã—ã€
è©²å½“ç®‡æ‰€ã‚’ç‰¹å®šã—ã¦å¼·èª¿è¡¨ç¤ºã—ã¾ã™ã€‚LLMã‚’ä½¿ç”¨ã—ã¦é«˜ç²¾åº¦ã«ä½ç½®ã‚’ç‰¹å®šã—ã¾ã™ã€‚
"""

import google.generativeai as genai
import os
import json
import re
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import logging
from dotenv import load_dotenv
from infra.config import PathManager, DirNames, cfg

# ==========================================
# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==========================================
# ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
# ==========================================

@dataclass
class QuoteLocation:
    """å¼•ç”¨ç®‡æ‰€ã®ä½ç½®æƒ…å ±"""
    quote: str                    # å¼•ç”¨æ–‡
    section_name: str             # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆbest_mode, background_artç­‰ï¼‰
    paragraph_index: int          # æ®µè½ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0å§‹ã¾ã‚Šï¼‰
    paragraph_id: str             # æ®µè½IDï¼ˆä¾‹: "[best_mode_0121]"ï¼‰
    start_char: int               # æ®µè½å†…ã®é–‹å§‹æ–‡å­—ä½ç½®
    end_char: int                 # æ®µè½å†…ã®çµ‚äº†æ–‡å­—ä½ç½®
    found: bool = True            # è¦‹ã¤ã‹ã£ãŸã‹ã©ã†ã‹
    confidence: str = "exact"     # ãƒãƒƒãƒãƒ³ã‚°ä¿¡é ¼åº¦ï¼ˆexact, partial, not_foundï¼‰

# ==========================================
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
# ==========================================

class QuoteLocatorPrompts:
    """å¼•ç”¨ç®‡æ‰€ç‰¹å®šç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"""

    SYSTEM_INSTRUCTION = """
ã‚ãªãŸã¯ç‰¹è¨±æ–‡çŒ®è§£æã®å°‚é–€å®¶ã§ã™ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ã€è¨¼æ‹ ã¨ã—ã¦æŠ½å‡ºã•ã‚ŒãŸå¼•ç”¨æ–‡ãŒã€å…ƒã®ç‰¹è¨±æ–‡çŒ®ã®ã©ã“ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ­£ç¢ºã«ç‰¹å®šã™ã‚‹ã“ã¨ã§ã™ã€‚

ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
1. **æ­£ç¢ºæ€§**: å¼•ç”¨æ–‡ã¨å®Œå…¨ã«ä¸€è‡´ã™ã‚‹ç®‡æ‰€ã‚’æ¢ã—ã¦ãã ã•ã„ã€‚
2. **æ®µè½ç•ªå·**: å®Ÿéš›ã®æ®µè½ç•ªå·ï¼ˆæ®µè½IDï¼‰ã‚’æ­£ç¢ºã«å ±å‘Šã—ã¦ãã ã•ã„ã€‚
3. **ä½ç½®æƒ…å ±**: æ®µè½å†…ã§ã®é–‹å§‹ä½ç½®ã¨çµ‚äº†ä½ç½®ï¼ˆæ–‡å­—æ•°ï¼‰ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
4. **æ—¥æœ¬èªå‡ºåŠ›**: ã™ã¹ã¦ã®å‡ºåŠ›ã¯æ—¥æœ¬èªã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
"""

    LOCATE_QUOTE = """
ä»¥ä¸‹ã®å¼•ç”¨æ–‡ãŒã€ç‰¹è¨±æ–‡çŒ®ã®ã©ã“ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

# å¼•ç”¨æ–‡
{quote}

# ç‰¹è¨±æ–‡çŒ®ï¼ˆæ®µè½ç•ªå·ä»˜ãï¼‰
{patent_text}

# ãƒ’ãƒ³ãƒˆæƒ…å ±
{hint_info}

# å‡ºåŠ›è¦ä»¶

å¼•ç”¨æ–‡ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

```json
{{
  "found": true,
  "section_name": "ã‚»ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆä¾‹: best_mode, background_artç­‰ï¼‰",
  "paragraph_id": "æ®µè½IDï¼ˆä¾‹: [best_mode_0121]ï¼‰",
  "paragraph_index": æ®µè½ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç•ªå·ï¼ˆ0å§‹ã¾ã‚Šï¼‰,
  "paragraph_text": "æ®µè½ã®å…¨æ–‡",
  "start_char": æ®µè½å†…ã§ã®å¼•ç”¨é–‹å§‹ä½ç½®ï¼ˆæ–‡å­—æ•°ï¼‰,
  "end_char": æ®µè½å†…ã§ã®å¼•ç”¨çµ‚äº†ä½ç½®ï¼ˆæ–‡å­—æ•°ï¼‰,
  "confidence": "exact",
  "reasoning": "ãªãœã“ã®ç®‡æ‰€ã ã¨åˆ¤æ–­ã—ãŸã‹ã®èª¬æ˜"
}}
```

å¼•ç”¨æ–‡ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

```json
{{
  "found": false,
  "reason": "è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸç†ç”±",
  "searched_sections": ["ç¢ºèªã—ãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³åã®ãƒªã‚¹ãƒˆ"],
  "confidence": "not_found"
}}
```

**é‡è¦**:
- å¼•ç”¨æ–‡ã¨å®Œå…¨ã«ä¸€è‡´ã™ã‚‹ç®‡æ‰€ã‚’æ¢ã—ã¦ãã ã•ã„ï¼ˆä¸€å­—ä¸€å¥åŒã˜ï¼‰
- æ®µè½IDã¯ç‰¹è¨±æ–‡çŒ®ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å®Ÿéš›ã®IDã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- start_charã¨end_charã¯æ®µè½ãƒ†ã‚­ã‚¹ãƒˆã®å…ˆé ­ã‹ã‚‰ã®æ–‡å­—æ•°ï¼ˆ0å§‹ã¾ã‚Šï¼‰ã§æŒ‡å®šã—ã¦ãã ã•ã„
- JSONã®ã¿ã‚’å‡ºåŠ›ã—ã€ä½™è¨ˆãªèª¬æ˜ã¯ä¸è¦ã§ã™

å¿…ãšæ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""

# ==========================================
# LLMå¼•ç”¨ç®‡æ‰€ç‰¹å®šã‚·ã‚¹ãƒ†ãƒ 
# ==========================================

class LLMQuoteLocator:
    """LLMã‚’ä½¿ç”¨ã—ã¦å¼•ç”¨ç®‡æ‰€ã‚’ç‰¹å®šã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(
        self,
        api_key: Optional[str] = None,
        model_name: Optional[str] = None,
        max_retries: int = 3
    ):
        """
        åˆæœŸåŒ–

        Args:
            api_key: Google AI APIã‚­ãƒ¼ï¼ˆNoneã®å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—ï¼‰
            model_name: ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«åï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
            max_retries: LLMå‘¼ã³å‡ºã—ã®æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
        """
        # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
        load_dotenv()

        # APIã‚­ãƒ¼ã®å–å¾—ï¼ˆå¼•æ•° > ç’°å¢ƒå¤‰æ•°ã®å„ªå…ˆé †ä½ï¼‰
        if api_key is None:
            api_key = os.getenv("GOOGLE_API_KEY")

        if not api_key:
            raise ValueError(
                "API Key is required. "
                "Please set GOOGLE_API_KEY in .env file or pass it as an argument."
            )

        # ãƒ¢ãƒ‡ãƒ«åã®è¨­å®šï¼ˆå¼•æ•° > config > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å„ªå…ˆé †ä½ï¼‰
        if model_name is None:
            model_name = cfg.gemini_llm_name

        genai.configure(api_key=api_key)

        # System Instructionã‚’è¨­å®š
        self.system_instruction = QuoteLocatorPrompts.SYSTEM_INSTRUCTION

        # JSONå¼·åˆ¶ãƒ¢ãƒ‡ãƒ«ï¼ˆsystem_instruction + JSON Modeï¼‰
        self.model = genai.GenerativeModel(
            model_name=model_name,
            system_instruction=self.system_instruction,
            generation_config={"response_mime_type": "application/json"}
        )

        self.max_retries = max_retries

        logger.info(f"LLMQuoteLocator initialized with model: {model_name}")

    def _call_llm_with_retry(self, prompt: str) -> Optional[str]:
        """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãLLMå‘¼ã³å‡ºã—"""
        final_prompt = prompt + "\n\nå¿…ãšæ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ (Output in Japanese)."

        for attempt in range(self.max_retries):
            try:
                response = self.model.generate_content(final_prompt)
                if response.text:
                    return response.text
            except Exception as e:
                logger.warning(f"LLM call attempt {attempt + 1} failed: {e}")
                if attempt == self.max_retries - 1:
                    logger.error("All retry attempts exhausted")
                    return None
        return None

    def _prepare_patent_text(self, patent_dict: Dict) -> Tuple[str, Dict[str, List[str]]]:
        """
        ç‰¹è¨±æ–‡çŒ®ã‚’æ®µè½ç•ªå·ä»˜ããƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›

        Returns:
            (formatted_text, section_map): ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ—
        """
        description = patent_dict.get("description", {})
        formatted_lines = []
        section_map = {}

        for section_name, content in description.items():
            if isinstance(content, dict):
                continue

            if isinstance(content, list):
                section_map[section_name] = []
                for idx, paragraph_text in enumerate(content):
                    if isinstance(paragraph_text, str) and paragraph_text.strip():
                        para_id = f"[{section_name}_{idx:04d}]"
                        formatted_lines.append(f"{para_id} {paragraph_text}")
                        section_map[section_name].append(paragraph_text)

            elif isinstance(content, str) and content.strip():
                para_id = f"[{section_name}]"
                formatted_lines.append(f"{para_id} {content}")
                section_map[section_name] = [content]

        return "\n".join(formatted_lines), section_map

    def _create_hint_info(self, source_paragraph: Optional[str]) -> str:
        """ãƒ’ãƒ³ãƒˆæƒ…å ±ã‚’ä½œæˆ"""
        if source_paragraph:
            return f"æ¨å®šã•ã‚Œã‚‹æ®µè½: {source_paragraph}"
        return "ãƒ’ãƒ³ãƒˆæƒ…å ±ãªã—"

    def locate_quote_in_patent(
        self,
        quote: str,
        patent_dict: Dict,
        source_paragraph_hint: Optional[str] = None
    ) -> QuoteLocation:
        """
        LLMã‚’ä½¿ç”¨ã—ã¦å¼•ç”¨æ–‡ã®ä½ç½®ã‚’ç‰¹å®šã™ã‚‹

        Args:
            quote: å¼•ç”¨æ–‡ï¼ˆä¸€å­—ä¸€å¥ãã®ã¾ã¾ï¼‰
            patent_dict: ç‰¹è¨±æ–‡çŒ®ã®è¾æ›¸
            source_paragraph_hint: æ®µè½IDã®ãƒ’ãƒ³ãƒˆï¼ˆä¾‹: "[best_mode_0121]"ï¼‰

        Returns:
            QuoteLocation: å¼•ç”¨ç®‡æ‰€ã®ä½ç½®æƒ…å ±
        """
        logger.info(f"ğŸ” LLMã§å¼•ç”¨ç®‡æ‰€ã‚’ç‰¹å®šä¸­: {quote[:50]}...")

        # ç‰¹è¨±æ–‡çŒ®ã‚’æº–å‚™
        patent_text, section_map = self._prepare_patent_text(patent_dict)
        hint_info = self._create_hint_info(source_paragraph_hint)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt = QuoteLocatorPrompts.LOCATE_QUOTE.format(
            quote=quote,
            patent_text=patent_text,
            hint_info=hint_info
        )

        # LLMå‘¼ã³å‡ºã—
        response = self._call_llm_with_retry(prompt)
        if not response:
            logger.warning(f"âŒ LLMå‘¼ã³å‡ºã—å¤±æ•—: {quote[:50]}...")
            return self._create_not_found_location(quote)

        # JSONãƒ‘ãƒ¼ã‚¹
        try:
            result = json.loads(response)
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e}")
            logger.debug(f"Response: {response}")
            return self._create_not_found_location(quote)

        # çµæœã®æ¤œè¨¼
        if not result.get("found"):
            logger.warning(f"âŒ è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {quote[:50]}...")
            return self._create_not_found_location(quote)

        # QuoteLocationã‚’ä½œæˆ
        section_name = result.get("section_name", "")
        paragraph_id = result.get("paragraph_id", "")
        paragraph_index = result.get("paragraph_index", -1)
        start_char = result.get("start_char", -1)
        end_char = result.get("end_char", -1)
        confidence = result.get("confidence", "exact")

        # æ¤œè¨¼: å®Ÿéš›ã«å¼•ç”¨ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        paragraph_text = result.get("paragraph_text", "")

        # åŸºæœ¬çš„ãªæ¤œè¨¼: å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
        if not paragraph_text or start_char < 0 or end_char <= start_char:
            logger.warning(f"âŒ ç„¡åŠ¹ãªãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ãŒè¿”ã•ã‚Œã¾ã—ãŸ")
            logger.debug(f"paragraph_text exists: {bool(paragraph_text)}, start: {start_char}, end: {end_char}")
            return self._create_not_found_location(quote)

        # å¼•ç”¨ã®ä¸€è‡´æ¤œè¨¼
        extracted_quote = paragraph_text[start_char:end_char]
        if self._normalize_text(extracted_quote) != self._normalize_text(quote):
            logger.warning(f"âš ï¸ æŠ½å‡ºã•ã‚ŒãŸå¼•ç”¨ãŒå…ƒã®å¼•ç”¨ã¨ä¸€è‡´ã—ã¾ã›ã‚“")
            logger.debug(f"Expected: {quote}")
            logger.debug(f"Got: {extracted_quote}")
            # ä¸€è‡´ã—ãªã„å ´åˆã¯è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã¨ã—ã¦æ‰±ã†
            return self._create_not_found_location(quote)

        logger.info(f"âœ… è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {paragraph_id} (confidence: {confidence})")

        return QuoteLocation(
            quote=quote,
            section_name=section_name,
            paragraph_index=paragraph_index,
            paragraph_id=paragraph_id,
            start_char=start_char,
            end_char=end_char,
            found=True,
            confidence=confidence
        )

    def _normalize_text(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ï¼ˆæ¯”è¼ƒç”¨ï¼‰"""
        # ç©ºç™½ã‚’çµ±ä¸€
        normalized = re.sub(r'\s+', ' ', text)
        return normalized.strip()

    def _create_not_found_location(self, quote: str) -> QuoteLocation:
        """è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã®QuoteLocationã‚’ä½œæˆ"""
        return QuoteLocation(
            quote=quote,
            section_name="",
            paragraph_index=-1,
            paragraph_id="",
            start_char=-1,
            end_char=-1,
            found=False,
            confidence="not_found"
        )

# ==========================================
# å¼·èª¿è¡¨ç¤ºæ©Ÿèƒ½
# ==========================================

def highlight_quote_in_paragraph(
    paragraph_text: str,
    quote: str,
    start_char: int,
    end_char: int,
    highlight_format: str = "html"
) -> str:
    """
    æ®µè½å†…ã®å¼•ç”¨ç®‡æ‰€ã‚’å¼·èª¿è¡¨ç¤º

    Args:
        paragraph_text: æ®µè½ã®ãƒ†ã‚­ã‚¹ãƒˆ
        quote: å¼•ç”¨æ–‡
        start_char: é–‹å§‹ä½ç½®
        end_char: çµ‚äº†ä½ç½®
        highlight_format: å¼·èª¿å½¢å¼ï¼ˆ"html", "markdown", "ansi", "brackets"ï¼‰

    Returns:
        å¼·èª¿è¡¨ç¤ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    before = paragraph_text[:start_char]
    highlighted = paragraph_text[start_char:end_char]
    after = paragraph_text[end_char:]

    if highlight_format == "html":
        return f'{before}<mark style="background-color: yellow; font-weight: bold;">{highlighted}</mark>{after}'
    elif highlight_format == "markdown":
        return f"{before}**{highlighted}**{after}"
    elif highlight_format == "ansi":
        # ANSI color codes
        YELLOW_BG = "\033[43m\033[30m"  # é»„è‰²èƒŒæ™¯ã€é»’æ–‡å­—
        RESET = "\033[0m"
        return f"{before}{YELLOW_BG}{highlighted}{RESET}{after}"
    else:  # brackets
        return f"{before}ã€{highlighted}ã€‘{after}"

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•°
# ==========================================

def process_evidence_items(
    evidence_data: List[Dict],
    patent_dict: Dict,
    output_format: str = "html",
    api_key: Optional[str] = None
) -> Dict:
    """
    è¨¼æ‹ ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‡¦ç†ã—ã¦å¼•ç”¨ç®‡æ‰€ã‚’å¼·èª¿è¡¨ç¤º

    Args:
        evidence_data: è¨¼æ‹ æŠ½å‡ºçµæœã®ãƒªã‚¹ãƒˆï¼ˆevidence_itemsï¼‰
        patent_dict: ç‰¹è¨±æ–‡çŒ®ï¼ˆ2021536169.jsonã®å½¢å¼ï¼‰
        output_format: å‡ºåŠ›å½¢å¼ï¼ˆ"html", "markdown", "ansi", "brackets"ï¼‰
        api_key: Google AI APIã‚­ãƒ¼ï¼ˆNoneã®å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰

    Returns:
        å¼·èª¿è¡¨ç¤ºã•ã‚ŒãŸçµæœã‚’å«ã‚€è¾æ›¸
    """
    locator = LLMQuoteLocator(api_key=api_key)
    results = []

    total_quotes = 0
    found_quotes = 0

    # å„è¨¼æ‹ ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‡¦ç†
    for evidence_item in evidence_data:
        if not isinstance(evidence_item, dict):
            continue

        evidence_result = {
            "claim_scope": evidence_item.get("claim_scope", ""),
            "assertion": evidence_item.get("assertion", ""),
            "citations": []
        }

        # å„å¼•ç”¨ã‚’å‡¦ç†
        citations = evidence_item.get("citations", [])
        for citation in citations:
            quote = citation.get("quote", "")
            source_paragraph = citation.get("source_paragraph", "")
            proves = citation.get("proves", "")

            if not quote:
                continue

            total_quotes += 1

            # LLMã§å¼•ç”¨ç®‡æ‰€ã‚’ç‰¹å®š
            location = locator.locate_quote_in_patent(
                quote=quote,
                patent_dict=patent_dict,
                source_paragraph_hint=source_paragraph
            )

            if location.found:
                found_quotes += 1

            citation_result = {
                "quote": quote,
                "proves": proves,
                "source_paragraph": source_paragraph,
                "location": {
                    "found": location.found,
                    "section_name": location.section_name,
                    "paragraph_index": location.paragraph_index,
                    "paragraph_id": location.paragraph_id,
                    "confidence": location.confidence
                }
            }

            # å¼•ç”¨ç®‡æ‰€ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€å¼·èª¿è¡¨ç¤ºã‚’ç”Ÿæˆ
            if location.found:
                section_content = patent_dict.get("description", {}).get(location.section_name, [])
                if isinstance(section_content, list) and location.paragraph_index < len(section_content):
                    paragraph_text = section_content[location.paragraph_index]

                    highlighted_text = highlight_quote_in_paragraph(
                        paragraph_text=paragraph_text,
                        quote=quote,
                        start_char=location.start_char,
                        end_char=location.end_char,
                        highlight_format=output_format
                    )

                    citation_result["highlighted_paragraph"] = highlighted_text
                    citation_result["original_paragraph"] = paragraph_text
                    citation_result["paragraph_number"] = location.paragraph_index + 1

            evidence_result["citations"].append(citation_result)

        # foundãŒFalseã®è¨¼æ‹ ã‚¢ã‚¤ãƒ†ãƒ ã‚‚å«ã‚ã‚‹
        if "found" in evidence_item and not evidence_item["found"]:
            evidence_result["found"] = False
            evidence_result["reason"] = evidence_item.get("reason", "")

        results.append(evidence_result)

    return {
        "doc_number": patent_dict.get("doc_number", ""),
        "invention_title": patent_dict.get("invention_title", ""),
        "evidence_count": len(results),
        "total_quotes": total_quotes,
        "found_quotes": found_quotes,
        "not_found_quotes": total_quotes - found_quotes,
        "success_rate": f"{(found_quotes/total_quotes*100):.1f}%" if total_quotes > 0 else "N/A",
        "highlighted_evidence": results
    }

# ==========================================
# HTMLå‡ºåŠ›ç”Ÿæˆé–¢æ•°
# ==========================================

def generate_html_output(result: Dict, output_path: str):
    """
    å¼·èª¿è¡¨ç¤ºã•ã‚ŒãŸHTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

    Args:
        result: process_evidence_itemsã®å‡ºåŠ›çµæœ
        output_path: å‡ºåŠ›HTMLãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    html_parts = []

    # HTMLãƒ˜ãƒƒãƒ€ãƒ¼
    html_parts.append("""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç‰¹è¨±å¼•ç”¨ç®‡æ‰€ã®å¼·èª¿è¡¨ç¤ºï¼ˆLLMç‰ˆï¼‰</title>
    <style>
        body {
            font-family: 'Yu Gothic', 'Meiryo', sans-serif;
            line-height: 1.8;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .header {
            background-color: #2c3e50;
            color: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
        }
        .header h1 {
            margin: 0 0 10px 0;
        }
        .stats {
            background-color: #ecf0f1;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
        }
        .stats-item {
            display: inline-block;
            margin-right: 30px;
        }
        .evidence-item {
            background-color: white;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .claim-scope {
            font-size: 1.2em;
            font-weight: bold;
            color: #2980b9;
            margin-bottom: 10px;
        }
        .assertion {
            background-color: #fff9e6;
            border-left: 4px solid #f39c12;
            padding: 10px;
            margin: 10px 0;
        }
        .citation {
            margin-top: 20px;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 5px;
        }
        .quote-box {
            background-color: #e8f4f8;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 10px 0;
            font-style: italic;
        }
        .location-info {
            color: #7f8c8d;
            font-size: 0.9em;
            margin: 5px 0;
        }
        .highlighted-paragraph {
            background-color: #ffffff;
            border: 2px solid #27ae60;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            line-height: 2;
        }
        mark {
            background-color: yellow;
            font-weight: bold;
            padding: 2px 4px;
        }
        .proves {
            color: #16a085;
            margin: 10px 0;
            font-weight: 500;
        }
        .not-found {
            color: #e74c3c;
            background-color: #fadbd8;
            padding: 10px;
            border-radius: 5px;
        }
        .separator {
            border-top: 2px dashed #bdc3c7;
            margin: 30px 0;
        }
        .llm-badge {
            background-color: #9b59b6;
            color: white;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.8em;
            margin-left: 10px;
        }
    </style>
</head>
<body>
""")

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    html_parts.append(f"""
    <div class="header">
        <h1>ğŸ“„ ç‰¹è¨±å¼•ç”¨ç®‡æ‰€ã®å¼·èª¿è¡¨ç¤ºãƒ¬ãƒãƒ¼ãƒˆ<span class="llm-badge">ğŸ¤– LLMç‰ˆ</span></h1>
        <p>ç‰¹è¨±ç•ªå·: {result['doc_number']}</p>
        <p>ç™ºæ˜ã®åç§°: {result['invention_title']}</p>
    </div>
    """)

    # çµ±è¨ˆæƒ…å ±
    html_parts.append(f"""
    <div class="stats">
        <div class="stats-item"><strong>è¨¼æ‹ æ•°:</strong> {result['evidence_count']}</div>
        <div class="stats-item"><strong>ç·å¼•ç”¨æ•°:</strong> {result['total_quotes']}</div>
        <div class="stats-item"><strong>ç™ºè¦‹æ•°:</strong> {result['found_quotes']}</div>
        <div class="stats-item"><strong>æœªç™ºè¦‹æ•°:</strong> {result['not_found_quotes']}</div>
        <div class="stats-item"><strong>æˆåŠŸç‡:</strong> {result['success_rate']}</div>
    </div>
    """)

    # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤ºï¼ˆè¨¼æ‹ ãŒãªã„å ´åˆï¼‰
    if 'warning' in result:
        html_parts.append(f"""
    <div class="not-found" style="margin: 20px 0; padding: 20px; font-size: 1.1em;">
        <h3>âš ï¸ è­¦å‘Š</h3>
        <p>{result['warning']}</p>
        <p style="margin-top: 15px;"><strong>å¯¾å‡¦æ–¹æ³•:</strong></p>
        <ul>
            <li>è¨¼æ‹ æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„</li>
            <li>ã¾ãŸã¯ã€evidence_extraction/{result['doc_number']}.json ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„</li>
        </ul>
    </div>
    """)

    # å„è¨¼æ‹ ã‚¢ã‚¤ãƒ†ãƒ 
    for idx, evidence in enumerate(result['highlighted_evidence'], 1):
        html_parts.append(f'<div class="evidence-item">')
        html_parts.append(f'<div class="claim-scope">ğŸ” è¨¼æ‹  {idx}: {evidence["claim_scope"]}</div>')
        html_parts.append(f'<div class="assertion"><strong>ä¸»å¼µ:</strong> {evidence["assertion"]}</div>')

        # foundãŒFalseã®å ´åˆ
        if "found" in evidence and not evidence["found"]:
            html_parts.append(f'<div class="not-found"><strong>âš ï¸ è©²å½“ç®‡æ‰€ãªã—:</strong> {evidence.get("reason", "")}</div>')
        else:
            # å¼•ç”¨ã‚’è¡¨ç¤º
            for cit_idx, citation in enumerate(evidence.get("citations", []), 1):
                html_parts.append(f'<div class="citation">')
                html_parts.append(f'<h3>å¼•ç”¨ {cit_idx}</h3>')

                html_parts.append(f'<div class="quote-box">"{citation["quote"]}"</div>')

                if citation.get("proves"):
                    html_parts.append(f'<div class="proves"><strong>è¨¼æ˜å†…å®¹:</strong> {citation["proves"]}</div>')

                location = citation.get("location", {})
                if location.get("found"):
                    confidence = location.get("confidence", "exact")
                    html_parts.append(f'<div class="location-info">ğŸ“ ä½ç½®: {location.get("paragraph_id", "")} ï¼ˆ{location.get("section_name", "")} ã‚»ã‚¯ã‚·ãƒ§ãƒ³, æ®µè½ {citation.get("paragraph_number", "")}ï¼‰ [ä¿¡é ¼åº¦: {confidence}]</div>')

                    if "highlighted_paragraph" in citation:
                        html_parts.append('<h4>ğŸ“Œ å…ƒã®æ®µè½ï¼ˆå¼·èª¿è¡¨ç¤ºï¼‰:</h4>')
                        html_parts.append(f'<div class="highlighted-paragraph">{citation["highlighted_paragraph"]}</div>')
                else:
                    html_parts.append(f'<div class="not-found">âŒ è©²å½“ç®‡æ‰€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ</div>')

                html_parts.append('</div>')  # citation

        html_parts.append('</div>')  # evidence-item

        if idx < result['evidence_count']:
            html_parts.append('<div class="separator"></div>')

    # HTMLãƒ•ãƒƒã‚¿ãƒ¼
    html_parts.append("""
</body>
</html>
""")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(html_parts))

    logger.info(f"ğŸ“„ HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")

# ==========================================
# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
# ==========================================

def highlight_quotes_entry(
    evidence_json_path: str,
    patent_json_path: str,
    output_json_path: Optional[str] = None,
    output_html_path: Optional[str] = None,
    api_key: Optional[str] = None
):
    """
    è¨¼æ‹ JSONã¨ç‰¹è¨±JSONã‹ã‚‰å¼•ç”¨ç®‡æ‰€ã‚’å¼·èª¿è¡¨ç¤ºï¼ˆLLMç‰ˆï¼‰

    Args:
        evidence_json_path: è¨¼æ‹ ãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆ2023120212.jsonå½¢å¼ï¼‰
        patent_json_path: ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆ2021536169.jsonå½¢å¼ï¼‰
        output_json_path: JSONå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        output_html_path: HTMLå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        api_key: Google AI APIã‚­ãƒ¼ï¼ˆNoneã®å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰

    Returns:
        å‡¦ç†çµæœã®è¾æ›¸
    """
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(evidence_json_path, 'r', encoding='utf-8') as f:
        evidence_data = json.load(f)

    with open(patent_json_path, 'r', encoding='utf-8') as f:
        patent_dict = json.load(f)

    # ç‰¹è¨±æ–‡çŒ®ã®doc_numberã‚’å–å¾—
    target_doc_number = patent_dict.get("doc_number", "")

    # è¨¼æ‹ ãƒ‡ãƒ¼ã‚¿ãŒé…åˆ—ã®å ´åˆã€target_doc_numberã¨ä¸€è‡´ã™ã‚‹è¦ç´ ã‚’æ¤œç´¢
    evidence_items = []
    if isinstance(evidence_data, list):
        # é…åˆ—å†…ã‹ã‚‰è©²å½“ã™ã‚‹doc_numberã®è¨¼æ‹ ã‚’æ¤œç´¢
        for item in evidence_data:
            if isinstance(item, dict) and item.get("doc_number") == target_doc_number:
                evidence_items = item.get("evidence_items", [])
                logger.info(f"âœ“ å¯¾è±¡æ–‡çŒ® {target_doc_number} ã®è¨¼æ‹ ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ")
                break
        else:
            # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è­¦å‘Šã‚’å‡ºåŠ›
            logger.warning(f"âš ï¸ evidence_dataã« doc_number={target_doc_number} ã®è¨¼æ‹ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            logger.warning(f"   åˆ©ç”¨å¯èƒ½ãªdoc_numbers: {[item.get('doc_number') for item in evidence_data if isinstance(item, dict)]}")
            # ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã“ã¨ã§ã€ã‚¨ãƒ©ãƒ¼ã§ã¯ãªãã€Œè¨¼æ‹ ãªã—ã€ã¨ã—ã¦å‡¦ç†
    else:
        # è¾æ›¸å½¢å¼ã®å ´åˆã¯å¾“æ¥é€šã‚Š
        evidence_items = evidence_data.get("evidence_items", [])

    # å‡¦ç†å®Ÿè¡Œ
    logger.info("="*70)
    logger.info("å¼•ç”¨ç®‡æ‰€ã®å¼·èª¿è¡¨ç¤ºã‚’é–‹å§‹ï¼ˆLLMç‰ˆï¼‰")
    logger.info("="*70)

    # è¨¼æ‹ ãŒãªã„å ´åˆã¯ã€ç©ºã®çµæœã‚’ç”Ÿæˆ
    if len(evidence_items) == 0:
        logger.warning(f"âš ï¸ è¨¼æ‹ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ç©ºã®çµæœã‚’ç”Ÿæˆã—ã¾ã™")
        result = {
            "doc_number": patent_dict.get("doc_number", ""),
            "invention_title": patent_dict.get("invention_title", ""),
            "evidence_count": 0,
            "total_quotes": 0,
            "found_quotes": 0,
            "not_found_quotes": 0,
            "success_rate": "N/A",
            "highlighted_evidence": [],
            "warning": f"ã“ã®æ–‡çŒ®ï¼ˆ{target_doc_number}ï¼‰ã®è¨¼æ‹ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è¨¼æ‹ æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        }
    else:
        result = process_evidence_items(
            evidence_data=evidence_items,
            patent_dict=patent_dict,
            output_format="html",
            api_key=api_key
        )

    # JSONçµæœã‚’ä¿å­˜
    if output_json_path:
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ JSONçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_json_path}")

    # HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    if output_html_path:
        generate_html_output(result, output_html_path)

    logger.info("\n" + "="*70)
    logger.info("å‡¦ç†å®Œäº†ï¼ˆLLMç‰ˆï¼‰")
    logger.info("="*70)
    logger.info(f"è¨¼æ‹ æ•°: {result['evidence_count']}")
    logger.info(f"ç·å¼•ç”¨æ•°: {result['total_quotes']}")
    logger.info(f"ç™ºè¦‹æ•°: {result['found_quotes']} ({result['success_rate']})")
    logger.info(f"æœªç™ºè¦‹æ•°: {result['not_found_quotes']}")

    return result

# ==========================================
# æ¨™æº–ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ãŸã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
# ==========================================

def generate_highlighted_html_for_reference(
    reference_doc_num: str,
    current_doc_number: str
) -> Dict:
    """
    å‚ç…§æ–‡çŒ®ç•ªå·ã‹ã‚‰è‡ªå‹•çš„ã«ãƒ‘ã‚¹ã‚’å–å¾—ã—ã¦HTMLã‚’ç”Ÿæˆ
    PathManagerã‚’ä½¿ç”¨ã—ã¦æ¨™æº–çš„ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‹ã‚‰ãƒ‘ã‚¹ã‚’å–å¾—ã™ã‚‹

    Args:
        reference_doc_num: å‚ç…§å…ˆè¡ŒæŠ€è¡“æ–‡çŒ®ç•ªå·
        current_doc_number: ç¾åœ¨å¯©æŸ»ä¸­ã®ç”³è«‹ç‰¹è¨±ã®ç•ªå·

    Returns:
        å‡¦ç†çµæœã®è¾æ›¸

    Raises:
        FileNotFoundError: å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    """
    # PathManagerã‹ã‚‰æ¨™æº–çš„ãªãƒ‘ã‚¹ã‚’å–å¾—
    evidence_json_path = PathManager.get_dir(
        current_doc_number,
        DirNames.EVIDENCE_EXTRACTION
    ) / f"{reference_doc_num}.json"

    patent_json_path = PathManager.get_dir(
        current_doc_number,
        DirNames.DOC_FULL_CONTENT
    ) / f"{reference_doc_num}.json"

    output_html_path = PathManager.get_dir(
        current_doc_number,
        DirNames.HIGHLIGHTED_EVIDENCE
    ) / f"{reference_doc_num}_highlighted.html"

    output_json_path = PathManager.get_dir(
        current_doc_number,
        DirNames.HIGHLIGHTED_JSON
    ) / f"{reference_doc_num}.json"

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not evidence_json_path.exists():
        raise FileNotFoundError(f"è¨¼æ‹ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {evidence_json_path}")

    if not patent_json_path.exists():
        raise FileNotFoundError(f"ç‰¹è¨±æ–‡çŒ®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {patent_json_path}")

    # æ—¢å­˜ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—
    logger.info(f"ğŸ“„ {reference_doc_num} ã®å¼·èª¿è¡¨ç¤ºHTML & JSONã‚’ç”Ÿæˆä¸­...")
    result = highlight_quotes_entry(
        evidence_json_path=str(evidence_json_path),
        patent_json_path=str(patent_json_path),
        output_json_path=str(output_json_path),
        output_html_path=str(output_html_path)
    )

    logger.info(f"âœ… {reference_doc_num} ã®å¼·èª¿è¡¨ç¤ºHTMLã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_html_path}")
    logger.info(f"âœ… {reference_doc_num} ã®JSONã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_json_path}")
    return result

# ==========================================
# ä½¿ç”¨ä¾‹
# ==========================================

if __name__ == "__main__":
    # ã‚µãƒ³ãƒ—ãƒ«ä½¿ç”¨ä¾‹
    import sys

    if len(sys.argv) < 3:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python 'Highlight patent quotes.py' <è¨¼æ‹ JSONãƒ‘ã‚¹> <ç‰¹è¨±JSONãƒ‘ã‚¹> [å‡ºåŠ›JSONãƒ‘ã‚¹] [å‡ºåŠ›HTMLãƒ‘ã‚¹]")
        print("\nä¾‹:")
        print("  python 'Highlight patent quotes.py' evidence.json patent.json output.json output.html")
        sys.exit(1)

    evidence_file = sys.argv[1]
    patent_file = sys.argv[2]
    output_json = sys.argv[3] if len(sys.argv) > 3 else None
    output_html = sys.argv[4] if len(sys.argv) > 4 else None

    try:
        result = highlight_quotes_entry(
            evidence_json_path=evidence_file,
            patent_json_path=patent_file,
            output_json_path=output_json,
            output_html_path=output_html
        )

        print("\nâœ… å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")

    except Exception as e:
        logger.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)